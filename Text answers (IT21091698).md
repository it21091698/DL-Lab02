# DL-Lab02
Deep Learning Module Lab 2 Answers are here

1) answer
   Expected Observations:
        Training Accuracy: Usually, as you increase the number of hidden nodes, the network's ability to fit the training data improves, leading to higher training                               accuracy.
        Generalization: However, if you add too many hidden nodes, the network might start to overfit the training data, meaning it learns the training examples too                          well and performs poorly on unseen data.
        Computation Cost: More hidden nodes increase the computational cost and training time, as there are more parameters to update during the training process

2)   1) answer
     Low Number of Hidden Nodes: The model might underfit, meaning it doesn't capture the underlying trend of the data well, leading to low accuracy.

     Optimal Number of Hidden Nodes: There's usually a "sweet spot" where the model has just enough hidden nodes to capture the complexity of the data without                                             overfitting. Here, you'll observe the highest accuracy on unseen data (validation set).

     Too Many Hidden Nodes: As mentioned earlier, adding too many hidden nodes can lead to overfitting, where the training accuracy might remain high, but the                                    validation accuracy (generalization) starts to drop.
